{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "The goal of this program is to visualize and cluster the data.\n",
    "\n",
    "## Input\n",
    "* Importing the libaries that are necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Importing the necessary files:\n",
    " * Read files\n",
    " * Convert read files to data\n",
    " * Save data in dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.388', '0.329', '0.69', '0.9', '0.626', '0.621', '0.399', '0.37']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv('Data\\Voorbeeld_clusterdata.txt', sep='  ', header=None, engine='python', index_col=0)\n",
    "df_results = pd.read_csv('Data\\Voorbeeld_clusterresult.txt', sep='  ', header=None, engine='python', index_col=0)\n",
    "df_clusterd = df_data.copy().drop(columns=df_data.columns)\n",
    "\n",
    "def lib(FileName):\n",
    "    def openFile(FileName):\n",
    "        read_data = open(f'{FileName}')\n",
    "        data = read_data.read()\n",
    "        data = data.splitlines()\n",
    "        read_data.close()\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    lib = {}\n",
    "    \n",
    "    for lines in openFile(FileName):\n",
    "        line = lines.split()\n",
    "        lib[line[0]] = line[1:]\n",
    "            \n",
    "    return lib\n",
    "\n",
    "lib_data = lib('Data\\Voorbeeld_clusterdata.txt')\n",
    "lib_results = lib('Data\\Voorbeeld_clusterresult.txt')\n",
    "\n",
    "lib_data['846160']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster methods\n",
    "### K-means (KMCA):\n",
    "\n",
    "uitleggen hoe het werkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMCA:\n",
    "    def __init__(self, k=6, tol=0.001, max_iter=300):\n",
    "        self.k = k\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "    def set_k(K):\n",
    "        self.k = K\n",
    "\n",
    "    def fit(self,data):\n",
    "\n",
    "        self.centroids = {}\n",
    "\n",
    "        for i in range(self.k):\n",
    "            self.centroids[i] = data[i]\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            self.classifications = {}\n",
    "\n",
    "            for i in range(self.k):\n",
    "                self.classifications[i] = []\n",
    "\n",
    "            for featureset in data:\n",
    "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
    "                classification = distances.index(min(distances))\n",
    "                self.classifications[classification].append(featureset)\n",
    "\n",
    "            prev_centroids = dict(self.centroids)\n",
    "\n",
    "            for classification in self.classifications:\n",
    "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
    "\n",
    "            optimized = True\n",
    "\n",
    "            for c in self.centroids:\n",
    "                original_centroid = prev_centroids[c]\n",
    "                current_centroid = self.centroids[c]\n",
    "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
    "                    optimized = False\n",
    "\n",
    "            if optimized:\n",
    "                break\n",
    "\n",
    "    def predict(self,data):\n",
    "        def pred(self, data):\n",
    "            distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
    "            classification = distances.index(min(distances))\n",
    "            return classification\n",
    "        \n",
    "        self.pred_classifications = list()\n",
    "        \n",
    "        if np.isfortran(data):\n",
    "            for element in data:\n",
    "                self.pred_classifications.append(pred(self, element))\n",
    "        else:\n",
    "            self.pred_classifications.append(pred(self, data))\n",
    "            \n",
    "        return self.pred_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Own cluster method: Grid based Cluster Algorithm (GCA)\n",
    "VERDERE UITLEG MOET NOG KOMEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCA:\n",
    "    \"\"\"\n",
    "    THIS CLASS USES LIBERARIES\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, r=1):\n",
    "        self.r = r\n",
    "    \n",
    "    def fit(self, data, j=10):\n",
    "        self.Indexes = list(data.keys())\n",
    "\n",
    "        def get_cordinates(data):\n",
    "            cordinates = dict()\n",
    "\n",
    "            for cor in range(len(self.Indexes[0])):\n",
    "                x = list()\n",
    "                for i in data:\n",
    "                    x.append(float(data[i][cor]))\n",
    "\n",
    "                cordinates[cor] = tuple(x)\n",
    "\n",
    "            return cordinates\n",
    "\n",
    "        def get_intervals(data,j):\n",
    "            dic = dict()\n",
    "\n",
    "            for i in cords:\n",
    "                minim = np.min(cords[i])\n",
    "                maxim = np.max(cords[i])\n",
    "\n",
    "                dic[i] = np.mgrid[minim:maxim:complex(0,j)]\n",
    "\n",
    "            return dic\n",
    "\n",
    "        def get_cells():\n",
    "            cordinates = get_cordinates(data)\n",
    "            intervals = get_intervals(cordinates,j)\n",
    "            \n",
    "            labels = list()\n",
    "            for i in cordinates:\n",
    "                x_inter_label = list()\n",
    "                for j in range(1,len(intervals[i])):\n",
    "                    vals = list((cords[i] >= intervals[i][j-1]) & (cords[i] < intervals[i][j]))\n",
    "                    vals = np.where(vals==False, 0, vals)\n",
    "                    vals = np.where(vals==True, j, vals)       \n",
    "\n",
    "                    x_inter_label.append(vals)\n",
    "\n",
    "                labels.append(x_inter_label)\n",
    "\n",
    "\n",
    "            labelzz = list()\n",
    "            for i in range(len(labels)):\n",
    "                for k in range(1,len(labels[i])):\n",
    "                    labels[i][0] = np.add(labels[i][0],labels[i][k])\n",
    "                labelzz.append(labels[i][0])\n",
    "\n",
    "            del labels\n",
    "\n",
    "            lib_cells = dict()     \n",
    "\n",
    "            for i in range(len(labelzz[0])):\n",
    "                cell_id = list()\n",
    "                for j in range(len(labelzz)):\n",
    "                    cell_id.append(labelzz[j][i])\n",
    "\n",
    "                lib_cells[IDs[i]] = cell_id\n",
    "                \n",
    "            return lib_cells\n",
    "        \n",
    "        def self_predict(self, data):\n",
    "            \"\"\"\n",
    "            DIT MOET NOG AANGEVULD WORDEN. WAT NOG MOET GEBEUREN:\n",
    "                1. GET NEIGBOURS AND DELETE NEIGB.ID FROM INDEX.LIST\n",
    "                2. SAVE NEIGBOUR-GROUPS IN GROUPS\n",
    "                -----\n",
    "                3. PREDICT \n",
    "            \n",
    "            \"\"\"\n",
    "            def get_labels(data):\n",
    "                def get_neigb_id(ID):\n",
    "                    neigb = list()\n",
    "                    for indx in lib_cells:\n",
    "                        distance = np.subtract(lib_cells[ID],lib_cells[indx],out=np.array([0 for i in range(8)]))\n",
    "                        if all([-1 < i < 1 for i in distance]):\n",
    "                            neigb.append(indx)\n",
    "\n",
    "                    return neigb\n",
    "\n",
    "                indexes = [id for id in data]\n",
    "                new_indexes = indexes.copy()\n",
    "\n",
    "                def make_groups(data_point):\n",
    "                    neigbors = get_neigb_id(data_point)\n",
    "                    new_neigbors = list()\n",
    "\n",
    "                    for cel in neigbors:\n",
    "                        new_cells = get_neigb_id(cel)\n",
    "\n",
    "                        for new_cel in new_cells:\n",
    "                            if new_cel not in neigbors:\n",
    "                                new_neigbors.append(new_cel)\n",
    "                                print(new_cel)\n",
    "\n",
    "                        neigbors += new_neigbors\n",
    "\n",
    "                    for neigb in neigbors:\n",
    "                        new_indexes.remove(neigb)\n",
    "\n",
    "                    return neigbors\n",
    "\n",
    "                options = list()\n",
    "\n",
    "                for index in new_indexes:\n",
    "                    options.append(make_groups(index))\n",
    "\n",
    "                return options\n",
    "            \n",
    "        def self_predict(self, data):\n",
    "            \"\"\"\n",
    "            VERZIN CODE DIE KIJKT WELKE CLUSTER DMV VAN CEL-ID GATHERING HET DICHTSTE BIJ IS\n",
    "            \n",
    "            \"\"\"\n",
    "        \n",
    "        return get_cells()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "* get cluster labels\n",
    "* save labels in text file\n",
    "\n",
    "### get cluster labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KMCA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>846160</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820434</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849103</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846353</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848613</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        KMCA\n",
       "0           \n",
       "846160     0\n",
       "820434     4\n",
       "849103     2\n",
       "846353     3\n",
       "848613     2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmca = KMCA()\n",
    "kmca.fit(df_data.values)\n",
    "df_clusterd['KMCA'] = kmca.predict(df_data.values)\n",
    "\n",
    "df_clusterd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusterd.to_csv(r'Data\\clusterresultaten.txt', header=None, index=True, sep=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
